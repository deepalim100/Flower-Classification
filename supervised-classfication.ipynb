{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nfrom operator import itemgetter\nimport copy\nimport time\nimport torch\nimport torchvision\nimport torchvision.transforms as transform\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\nimport torch.nn.functional as F\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.image import imread\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice= torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-17T21:58:54.108056Z","iopub.execute_input":"2022-07-17T21:58:54.108485Z","iopub.status.idle":"2022-07-17T21:58:57.071122Z","shell.execute_reply.started":"2022-07-17T21:58:54.108399Z","shell.execute_reply":"2022-07-17T21:58:57.070188Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Steps for training\n\n* Initialize the tranformer\n* Create the dataloaders for training, test & validation\n* Intialize models\n* Intialize the training\n* Evaluate the model on test set\n* Desiging the KPI : [ Confusion Matrix ]","metadata":{}},{"cell_type":"code","source":"# Initializing the transformer\ntransformer = {\n    'original': transform.Compose([\n                                 transform.Resize((220, 220)),\n                                 transform.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n                                 transform.RandomRotation(5),\n                                 transform.RandomAffine(degrees=11, translate=(0.1,0.1), scale=(0.8,0.8)),\n                                 transform.ToTensor(),\n                                 transform.Normalize((0.4124234616756439, 0.3674212694168091, 0.2578217089176178), \n                                               (0.3268945515155792, 0.29282665252685547, 0.29053378105163574)),\n]),\n    'test' : transform.Compose([\n                                 transform.Resize((220, 220)),\n                                 transform.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n                                 transform.ToTensor(),\n                                 transform.Normalize((0.4124234616756439, 0.3674212694168091, 0.2578217089176178), \n                                               (0.3268945515155792, 0.29282665252685547, 0.29053378105163574)),\n])}\n\n####################################################################################################\nbs = 50\ntrain_path = '../input/flower-dataset/train'\noriginal = ImageFolder(train_path, transform=transformer['original'])\ntest_path = '../input/flower-dataset/test'\ntest = ImageFolder(test_path, transform=transformer['test'])\n# Splitting the train & test dataset\ntrain, val = train_test_split(original, test_size=0.2, shuffle=True, random_state=43)\nloaders = {\n    'train': DataLoader(train, batch_size=bs, num_workers=0, pin_memory=True),\n    'val': DataLoader(val, batch_size=bs, num_workers=0, pin_memory=True),\n    'test': DataLoader(test, batch_size=bs, num_workers=0, pin_memory=True)\n}\n\ndataset_sizes = {\n    'train': len(train),\n    'val': len(val), \n    'test': len(test),\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-17T21:58:57.074595Z","iopub.execute_input":"2022-07-17T21:58:57.074873Z","iopub.status.idle":"2022-07-17T22:00:28.980167Z","shell.execute_reply.started":"2022-07-17T21:58:57.074844Z","shell.execute_reply":"2022-07-17T22:00:28.979174Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# accuracy to measure the model\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds\n\n#save the losses for further visualization\nlosses = {'train':[], 'val':[]}\naccuracies = {'train':[], 'val':[]}\nlr = []","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:00:44.997649Z","iopub.execute_input":"2022-07-17T22:00:44.998008Z","iopub.status.idle":"2022-07-17T22:00:45.003626Z","shell.execute_reply.started":"2022-07-17T22:00:44.997975Z","shell.execute_reply":"2022-07-17T22:00:45.002331Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def train(epochs, model):    \n  print('----------------------Creating a model -----------------------')\n  PATH = '../input/ssl-model/resnet18_best.pth'\n  model.to(device)  \n  criterion = nn.CrossEntropyLoss()\n  optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay = 1e-5)\n  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  state_dict = torch.load(PATH,map_location=device)\n  best_model = model.load_state_dict(state_dict, strict=False)\n  best_acc = 0.0\n  for epoch in range(epochs):\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n      else:\n        model.eval()      \n      running_loss = 0.0\n      running_corrects = 0.0\n      for inputs, labels in loaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(phase=='train'):\n          outp = model(inputs)\n          _, pred = torch.max(outp, 1)\n          loss = criterion(outp, labels) \n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item()*inputs.size(0)\n        running_corrects += torch.sum(pred == labels.data)\n\n      if phase == 'train':\n          acc = 100. * running_corrects.double() / dataset_sizes[phase]\n          scheduler.step(acc)\n\n      epoch_loss = running_loss / dataset_sizes[phase]\n      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n      losses[phase].append(epoch_loss)\n      accuracies[phase].append(epoch_acc)\n      if phase == 'train':\n        print('Epoch: {}/{}'.format(epoch+1, epochs))\n      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n      lr.append(scheduler._last_lr)\n        \n      if phase == 'val':\n        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n        print('=='*31)\n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model = copy.deepcopy(model.state_dict())\n    #scheduler.step() \n      state = {\n        'epoch': epoch,\n        'state_dict': model.state_dict(),\n        'optimizer': optimizer.state_dict()\n          }\n      Path = './saved_model.pth'\n      torch.save(state, Path)\n  time_elapsed = time.time() - since\n  print('CLASSIFIER TRAINING TIME {}m {}s'.format(time_elapsed//60, time_elapsed%60))\n  print('=='*31)\n  ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:00:45.528032Z","iopub.execute_input":"2022-07-17T22:00:45.528419Z","iopub.status.idle":"2022-07-17T22:00:45.544258Z","shell.execute_reply.started":"2022-07-17T22:00:45.528385Z","shell.execute_reply":"2022-07-17T22:00:45.543188Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**GoogleNet**","metadata":{}},{"cell_type":"code","source":"googlenet = torchvision.models.googlenet(pretrained=True)\nfor param in googlenet.parameters():\n  param.grad_requires = False\n\ngooglenet.fc = nn.Linear(in_features=googlenet.fc.in_features, out_features=len(original.classes), bias=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:00:47.006641Z","iopub.execute_input":"2022-07-17T22:00:47.006985Z","iopub.status.idle":"2022-07-17T22:00:47.230862Z","shell.execute_reply.started":"2022-07-17T22:00:47.006950Z","shell.execute_reply":"2022-07-17T22:00:47.229941Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Training ","metadata":{}},{"cell_type":"code","source":"epochs = 50\nmodels = googlenet\nmodel = train(epochs=epochs, model=models)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:00:49.115988Z","iopub.execute_input":"2022-07-17T22:00:49.116385Z","iopub.status.idle":"2022-07-17T22:14:20.586011Z","shell.execute_reply.started":"2022-07-17T22:00:49.116348Z","shell.execute_reply":"2022-07-17T22:14:20.584957Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Loss and Accuracy Plots","metadata":{}},{"cell_type":"code","source":"#  Plot train lacc and test accuracy \nplt.figure(figsize=(12,8))\nplt.plot(accuracies['train'],label = 'train Acc')\nplt.plot(accuracies['val'],label  = 'test Acc')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T21:37:51.281185Z","iopub.execute_input":"2022-07-17T21:37:51.283288Z","iopub.status.idle":"2022-07-17T21:37:51.475662Z","shell.execute_reply.started":"2022-07-17T21:37:51.283234Z","shell.execute_reply":"2022-07-17T21:37:51.474808Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#  Plot train and test loss\nplt.figure(figsize=(12,8))\nplt.plot(losses['train'],label = 'train loss')\nplt.plot(losses['val'],label  = 'test loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T21:37:55.586682Z","iopub.execute_input":"2022-07-17T21:37:55.587019Z","iopub.status.idle":"2022-07-17T21:37:55.745646Z","shell.execute_reply.started":"2022-07-17T21:37:55.586986Z","shell.execute_reply":"2022-07-17T21:37:55.744676Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation on test data","metadata":{}},{"cell_type":"code","source":"model = googlenet","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:16:49.866542Z","iopub.execute_input":"2022-07-17T22:16:49.866882Z","iopub.status.idle":"2022-07-17T22:16:49.871479Z","shell.execute_reply.started":"2022-07-17T22:16:49.866851Z","shell.execute_reply":"2022-07-17T22:16:49.869764Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def validation_step(batch):\n        images,labels = batch\n        images,labels = images.to(device),labels.to(device)\n        out = model(images)                                      \n        loss = F.cross_entropy(out, labels)                    \n        acc,preds = accuracy(out, labels)                       \n        \n        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n                'preds':preds.detach(), 'labels':labels.detach()}\n    \ndef test_prediction(outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()           \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()             \n        # combine predictions\n        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n        # combine labels\n        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n        \n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n                'test_preds': batch_preds, 'test_labels': batch_labels}","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:16:52.816678Z","iopub.execute_input":"2022-07-17T22:16:52.817038Z","iopub.status.idle":"2022-07-17T22:16:52.825810Z","shell.execute_reply.started":"2022-07-17T22:16:52.816994Z","shell.execute_reply":"2022-07-17T22:16:52.824862Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef test_predict(model, test_loader):\n    model.eval()\n    # perform testing for each batch\n    outputs = [validation_step(batch) for batch in test_loader] \n    results = test_prediction(outputs)                          \n    print('test_loss: {:.4f}, test_acc: {:.4f}'\n          .format(results['test_loss'], results['test_acc']))\n    \n    return results['test_preds'], results['test_labels']","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:16:53.106874Z","iopub.execute_input":"2022-07-17T22:16:53.107246Z","iopub.status.idle":"2022-07-17T22:16:53.112725Z","shell.execute_reply.started":"2022-07-17T22:16:53.107211Z","shell.execute_reply":"2022-07-17T22:16:53.111782Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.to(device)\npreds,labels = test_predict(model, loaders['test'])","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:16:54.546368Z","iopub.execute_input":"2022-07-17T22:16:54.546714Z","iopub.status.idle":"2022-07-17T22:17:06.051438Z","shell.execute_reply.started":"2022-07-17T22:16:54.546682Z","shell.execute_reply":"2022-07-17T22:17:06.050489Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### KPI Metrics","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open('../input/cat-json/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)\n\nclass_names = original.classes\n# changing categories to their actual names \nfor i in range(0,len(class_names)):\n    class_names[i] = cat_to_name.get(class_names[i])","metadata":{"execution":{"iopub.status.busy":"2022-07-17T21:53:57.789254Z","iopub.execute_input":"2022-07-17T21:53:57.789617Z","iopub.status.idle":"2022-07-17T21:53:57.796493Z","shell.execute_reply.started":"2022-07-17T21:53:57.789584Z","shell.execute_reply":"2022-07-17T21:53:57.794874Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"report = classification_report(labels, preds,\n                               output_dict=True,\n                               target_names=original.classes)\nreport_df = pd.DataFrame(report).transpose()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:17:06.053032Z","iopub.execute_input":"2022-07-17T22:17:06.053356Z","iopub.status.idle":"2022-07-17T22:17:06.082644Z","shell.execute_reply.started":"2022-07-17T22:17:06.053324Z","shell.execute_reply":"2022-07-17T22:17:06.081833Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_rows\", None)\nreport_df.head(134)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:17:06.084386Z","iopub.execute_input":"2022-07-17T22:17:06.084886Z","iopub.status.idle":"2022-07-17T22:17:06.119535Z","shell.execute_reply.started":"2022-07-17T22:17:06.084844Z","shell.execute_reply":"2022-07-17T22:17:06.118697Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Plot confusion matrix\ncm  = confusion_matrix(labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(19,19),cmap=plt.cm.Blues)\nplt.xticks(range(len(original.classes)), original.classes, fontsize=16)\nplt.yticks(range(len(original.classes)), original.classes, fontsize=16)\nplt.xlabel('Predicted Label',fontsize=18)\nplt.ylabel('True Label',fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T22:17:14.148702Z","iopub.execute_input":"2022-07-17T22:17:14.149069Z","iopub.status.idle":"2022-07-17T22:17:42.647814Z","shell.execute_reply.started":"2022-07-17T22:17:14.149032Z","shell.execute_reply":"2022-07-17T22:17:42.646856Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}